{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704fc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀入向量空間模型，給定任一篇文件，以kNN演算法自動判斷類別\n",
    "#Big Data & Business Analytics, Willie Yang, National Taiwan University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe06e4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7393x108 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 173482 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "X = sparse.load_npz(\"limit_model.npz\") #讀入稀疏矩陣\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ef2b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#以下套用之前範例讀入詞彙集\n",
    "import csv\n",
    "\n",
    "termset=dict() #用字典預備儲存所有詞彙\n",
    "no=0 #幫詞彙編號\n",
    "\n",
    "f = open('limit_up_term.csv', newline='', encoding='utf-8') #開檔 \n",
    "rows = csv.reader(f, delimiter=',') #讀檔\n",
    "for row in rows:\n",
    "  if row[0] not in termset: #如果是新詞彙則加入(意思是重複的不列入)\n",
    "    termset[row[0]]=no\n",
    "    no+=1\n",
    "f.close()\n",
    "\n",
    "f = open('limit_down_term.csv', newline='', encoding='utf-8') #開檔 \n",
    "rows = csv.reader(f, delimiter=',') #讀檔\n",
    "for row in rows:\n",
    "  if row[0] not in termset: #如果是新詞彙則加入(意思是重複的不列入)\n",
    "    termset[row[0]]=no\n",
    "    no+=1\n",
    "f.close()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9022a11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "  Welcome to MONPA: Multi-Objective NER POS Annotator for Chinese\n",
      "+---------------------------------------------------------------------+\n",
      "已找到 model檔。Found model file.\n",
      " PC 品牌 大廠 華碩 2357 16 舉行 法說會 顯示卡 PC 需求 暢旺 帶動 華碩 去年 品牌 毛利率 營益率 淨利率 純益 大增 68 創下 歷史 純益 EPS 60 股本 華碩 今日 公布 去年 品牌 財報 毛利率 20.3 年增 3.1 百分點 營益率 9.6 年增 百分點 純益 445.5 年增 68 淨利率 8.9 年增 百分點 純益 60\n"
     ]
    }
   ],
   "source": [
    "#給定任何一段內容當作查詢\n",
    "query='PC品牌大廠華碩（2357）今（16）日舉行線上法說會，受惠顯示卡及PC需求暢旺，\\\n",
    "  帶動華碩去年品牌毛利率、營益率、淨利率「三率三升」，稅後純益大增68%，創下歷史新高，\\\n",
    "  全年每股純益（EPS）達60元，大賺近6個股本。華碩今日公布去年品牌財報，毛利率20.3%，\\\n",
    "  年增3.1個百分點。營益率9.6%，年增3個百分點。稅後純益445.5億元，年增68%。\\\n",
    "  淨利率8.9%，年增2個百分點。全年每股純益達60元'\n",
    "\n",
    "#以下套用斷詞小範例\n",
    "import monpa\n",
    "from monpa import utils\n",
    "str='' #暫存本篇斷詞後的內容用\n",
    "sentence_list = utils.short_sentence(query) #斷句\n",
    "for item in sentence_list:\n",
    "  result_cut = monpa.cut(item) #斷詞\n",
    "  for term in result_cut:\n",
    "    term=term.strip() #去除前後多餘空白\n",
    "    if(len(term)>1): #若詞長>1\n",
    "      str=str+' '+term\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70a64c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 101)\t0.31622776601683794\n",
      "  (0, 77)\t0.31622776601683794\n",
      "  (0, 76)\t0.31622776601683794\n",
      "  (0, 64)\t0.31622776601683794\n",
      "  (0, 62)\t0.31622776601683794\n",
      "  (0, 58)\t0.6324555320336759\n",
      "  (0, 34)\t0.31622776601683794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/opt/anaconda3/envs/monpa-env/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1380: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(vocabulary=termset,use_idf=True) #用給定的termset建構向量，並使用idf加權 (這邊作法值得商榷)\n",
    "q=vectorizer.fit_transform([str]) #將查詢也套入同一個向量空間\n",
    "print(q[0:1]) #印出該向量做觀察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af99356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2147 4158   27 7127  870 4863  968]\n"
     ]
    }
   ],
   "source": [
    "#以下套用之前範例計算相似文件\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_similarities = linear_kernel(q[0:1], X).flatten() #與給定文件集的向量做相似度計算\n",
    "related_docs_indices = cosine_similarities.argsort() #將相似度由小至大做排序，並轉換成文件編號\n",
    "d=related_docs_indices[:-8:-1] #從後面取7個文件編號 (也就是相似度最大的前7名)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44859fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_up: 5 pred_down: 2\n",
      "pred_label: up\n"
     ]
    }
   ],
   "source": [
    "#以kNN相似文件來投票決定類別\n",
    "pred_up=0\n",
    "pred_down=0\n",
    "for i in d:\n",
    "  if(i>=4195): #已知文件編號0~4194為漲停，4195~7393為跌停，故依此範圍判定 (此為取巧權宜作法)\n",
    "    pred_down+=1 #票數加1\n",
    "  else:\n",
    "    pred_up+=1 #票數加1\n",
    "print('pred_up:', pred_up, 'pred_down:', pred_down)\n",
    "\n",
    "if(pred_up>pred_down):\n",
    "  print('pred_label: up') #判定為漲停\n",
    "elif(pred_up<pred_down):\n",
    "  print('pred_label: down') #判定為跌停\n",
    "else:\n",
    "  print('pred_label: even') #票數平手 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f106577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (monpa)",
   "language": "python",
   "name": "monpa-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
